# convolution in backpropagation

This section is by far the one I had the hardest time writing.

Recall that in each convolution layer, we have for input an image matrix, either the image from the outside or one generated by another convolution layer. Then we apply a cross-correlation, then an activation function and finally a max pooling.

We can say:

![sdasd](https://latex.codecogs.com/svg.image?k^{(t+1)}_{ij}=k^{(t)}_{ij}-\eta\frac{\partial&space;L}{\partial&space;k^{(t)}_{ij}})

If we take into account each ij and start applying the multiple chain rule with respect to z (the output of the cross-correlation), we will start to see a pattern that starts to repeat a cross-correlation.

